# ğŸ” LLM-Powered JSON-LD Anomaly Detection for Cybersecurity

This project is a research-driven application that uses a Large Language Model (LLM) to detect anomalies in structured forensic data formats (like JSON-LD) commonly found in cybersecurity investigations.

Built with **FastAPI**, **FAISS**, **Sentence Transformers**, and run locally using **Mistral via Ollama**, this system offers an explainable, efficient, and scalable way to analyze thousands of log records and pinpoint unusual patterns without relying on predefined rules.

---

## ğŸ“Œ Key Features

* âœ… **Upload and analyze JSON-LD files**
* âœ… **LLM-based anomaly detection using Mistral (Ollama)**
* âœ… **Automatic record compression and pattern grouping**
* âœ… **RAG (Retrieval-Augmented Generation)** using FAISS + LangChain
* âœ… **Strict response formatting** (Anomaly Detected: True/False + Description)
* âœ… Runs 100% **locally**, no external LLM calls

---

## ğŸ§  Use Case

Forensic analysts and cyber researchers often deal with thousands of structured records like MFT, USNJRNL, or EventLogs in UCO-based JSON-LD formats. This system:

* Groups repetitive records (e.g., same timestamp/event type)
* Compresses content into semantic summaries
* Sends it to an LLM with forensic case patterns retrieved from a knowledge base
* Gets back structured, explainable anomaly decisions

---

## ğŸ“ Project Structure

```
rag-anomaly-detector/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py               # FastAPI entry point
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â””â”€â”€ analyze.py        # File upload + trigger analysis
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ parser_service.py # JSON-LD parsing and compression
â”‚   â”‚   â”œâ”€â”€ rag_service.py    # FAISS retrieval + Mistral prompt
â”‚   â”‚   â””â”€â”€ embedding_service.py # Document embedding for KB
â”‚   â”œâ”€â”€ models/               # (Optional Pydantic schemas)
â”‚   â””â”€â”€ utils/                # File handlers, helpers
â”œâ”€â”€ vectorstore/              # Saved FAISS index
â”œâ”€â”€ documents/                # USECASE 1 & 2 .docx files
â”œâ”€â”€ uploads/                  # Uploaded user files
â”œâ”€â”€ embed_docs.py             # One-time KB embedding
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
```

---

## ğŸš€ Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/yourname/rag-anomaly-detector.git
cd rag-anomaly-detector
```

### 2. Set up a virtual environment and install dependencies

```bash
python -m venv venv
venv\Scripts\activate      # Windows
# or
source venv/bin/activate   # macOS/Linux

pip install -r requirements.txt
```

### 3. Pull Mistral via Ollama

```bash
ollama pull mistral
```

### 4. Run document embedding

```bash
python embed_docs.py
```

### 5. Start the FastAPI server

```bash
uvicorn app.main:app --reload
```

Visit [http://localhost:8000/docs](http://localhost:8000/docs) to test the API.

---

## ğŸ“¥ How It Works

1. User uploads a `.jsonld` file via `/api/analyze`
2. The file is parsed and grouped by `(timestamp, eventType)`
3. Repetitive records are collapsed to semantic summaries
4. Relevant forensic patterns are retrieved from embedded case documents using FAISS
5. A structured prompt is sent to Mistral
6. Mistral responds using a strict format:

   ```
   Anomaly Detected : True
   Description: ...
   ```
7. Response is returned via API

---

## ğŸ“Œ Prompt Format Used

```
You are a digital forensic analyst.

Here is forensic event data extracted from a JSON-LD file uploaded by the user:
---
<compressed_record_summary>
---

Here are known forensic patterns from previous cases this is a knowledge-base for you.
As this is a knowledge-base use these only as general references, not as facts in your explanation:
---
<retrieved_context_from_FAISS>
---

Now, can you identify any anomalies in the json-ld file uploaded by the user?
If yes, explain clearly, and do not mention anything from the knowledge-base. Stick to inferencing.

Output format:
Anomaly Detected : True/False
Description: ...
```

---

## âš ï¸ Limitations

* Only supports `.jsonld` files for now
* Requires manual embedding of new knowledge base documents
* Model context window limit (\~8K for Mistral)

---

## ğŸ”® Future Improvements

* GUI with Streamlit for interactive uploads
* CSV/Docx support
* Anomaly explanation with source facet IDs
* Run on high-context models (Claude, GPT-4 Turbo)
* Add rule-based validation layer pre-LLM

---

## ğŸ‘¨â€ğŸ’» Author

**Aldric Pinto**
